{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Shibuya Scramble (.b3dm -> .glb) extraction (Kaggle Notebook)\n",
        "\n",
        "このノートブックは PLATEAU の渋谷区データセット（plateau-13113-shibuya-ku-2023）をインストールし、3D Tiles（.b3dm）内に埋め込まれた glb をスクランブル交差点付近の範囲で抽出して ZIP 化するためのものです。\n",
        "\n",
        "事前準備（Kaggle）:\n",
        "- Notebook の右上「Settings」→ Internet を ON にしてください。\n",
        "- ディスク容量には制限があります。必要に応じて bbox を狭めてください。\n",
        "\n",
        "使い方:\n",
        "1. セルを上から順に実行します。\n",
        "2. 実行完了後、`/kaggle/working/output_glb.zip` をダウンロードしてください（Kaggle の右ペイン → Output）。\n",
        "\n",
        "必要なら ZIP をこちらにアップロードしてください。私の方で中身を確認し、不要なモデルの削除や結合・gltf 展開を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# 1) 必要パッケージをインストール\n",
        "!pip install -q 'plateaukit[all]' tqdm trimesh pygltflib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# 2) PLATEAU データセットをインストール / prebuild（時間がかかる場合があります）\n",
        "# ※ すでにインストール済みの場合はスキップされます\n",
        "!plateaukit install plateau-13113-shibuya-ku-2023 -y\n",
        "!plateaukit prebuild plateau-13113-shibuya-ku-2023 -t bldg -t tran -t brid -y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# 3) tileset.json を検索し、指定 bbox に交差するタイルから .b3dm 内蔵 glb を抽出して zip 化\n",
        "import json, struct, shutil\n",
        "from pathlib import Path\n",
        "from plateaukit import load_dataset\n",
        "\n",
        "DATASET_ID = \"plateau-13113-shibuya-ku-2023\"\n",
        "# スクランブル交差点周辺の bbox（必要に応じて調整）: lon_min, lat_min, lon_max, lat_max\n",
        "TARGET_BBOX = (139.6996, 35.6588, 139.7014, 35.6602)\n",
        "\n",
        "OUT_DIR = Path('/kaggle/working/output_glb')\n",
        "ZIP_PATH = Path('/kaggle/working/output_glb.zip')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def bbox_intersect(region, target_bbox):\n",
        "    west, south, east, north = region[0], region[1], region[2], region[3]\n",
        "    lon_min, lat_min, lon_max, lat_max = target_bbox\n",
        "    if lon_max < west or lon_min > east: return False\n",
        "    if lat_max < south or lat_min > north: return False\n",
        "    return True\n",
        "\n",
        "def extract_b3dm_to_glb_bytes(data: bytes):\n",
        "    if len(data) < 28:\n",
        "        raise ValueError('b3dm too small')\n",
        "    magic = data[0:4].decode('ascii', errors='ignore')\n",
        "    if magic != 'b3dm':\n",
        "        raise ValueError('not b3dm')\n",
        "    ftJsonLen = struct.unpack_from('<I', data, 12)[0]\n",
        "    ftBinLen = struct.unpack_from('<I', data, 16)[0]\n",
        "    btJsonLen = struct.unpack_from('<I', data, 20)[0]\n",
        "    btBinLen = struct.unpack_from('<I', data, 24)[0]\n",
        "    glb_offset = 28 + ftJsonLen + ftBinLen + btJsonLen + btBinLen\n",
        "    byteLength = struct.unpack_from('<I', data, 8)[0]\n",
        "    end = byteLength if (byteLength <= len(data) and byteLength > glb_offset) else len(data)\n",
        "    return data[glb_offset:end]\n",
        "\n",
        "print('Loading dataset object via plateaukit...')\n",
        "ds = load_dataset(DATASET_ID)\n",
        "dataset_root = None\n",
        "for attr in ('root','path','root_path','_root'):\n",
        "    if hasattr(ds, attr):\n",
        "        candidate = getattr(ds, attr)\n",
        "        if isinstance(candidate, str):\n",
        "            dataset_root = Path(candidate).resolve(); break\n",
        "        if isinstance(candidate, Path):\n",
        "            dataset_root = candidate.resolve(); break\n",
        "\n",
        "if dataset_root is None:\n",
        "    # fallback: search common locations\n",
        "    home = Path.home()\n",
        "    possible = [home / '.plateaukit', home / '.cache' / 'plateaukit', Path.cwd()]\n",
        "    found = None\n",
        "    for base in possible:\n",
        "        if not base.exists():\n",
        "            continue\n",
        "        for p in base.rglob('tileset.json'):\n",
        "            if DATASET_ID in str(p):\n",
        "                found = p.parent\n",
        "                break\n",
        "        if found:\n",
        "            dataset_root = found\n",
        "            break\n",
        "\n",
        "if dataset_root is None:\n",
        "    # brute force search under home (may be slow)\n",
        "    for p in Path.home().rglob('tileset.json'):\n",
        "        if DATASET_ID in str(p):\n",
        "            dataset_root = p.parent\n",
        "            break\n",
        "\n",
        "if dataset_root is None:\n",
        "    raise SystemExit('dataset root not found. Check plateaukit install / plateaukit info')\n",
        "\n",
        "print('Detected dataset root:', dataset_root)\n",
        "tileset_paths = list(dataset_root.rglob('tileset.json'))\n",
        "print('Found tileset.json count:', len(tileset_paths))\n",
        "\n",
        "extracted = 0\n",
        "processed = set()\n",
        "\n",
        "def process_tile(tile, base_path):\n",
        "    global extracted\n",
        "    bv = tile.get('boundingVolume', {})\n",
        "    region = bv.get('region')\n",
        "    intersects = True\n",
        "    if region:\n",
        "        intersects = bbox_intersect(region, TARGET_BBOX)\n",
        "    content = tile.get('content')\n",
        "    if intersects and content:\n",
        "        uri = content.get('uri') or content.get('url')\n",
        "        if uri:\n",
        "            absolute = (base_path / uri).resolve()\n",
        "            if absolute.exists():\n",
        "                if absolute.suffix.lower() == '.b3dm' and absolute not in processed:\n",
        "                    processed.add(absolute)\n",
        "                    try:\n",
        "                        data = absolute.read_bytes()\n",
        "                        glb = extract_b3dm_to_glb_bytes(data)\n",
        "                        outp = OUT_DIR / (absolute.stem + '.glb')\n",
        "                        outp.write_bytes(glb)\n",
        "                        print('Extracted:', outp)\n",
        "                        extracted += 1\n",
        "                    except Exception as e:\n",
        "                        print('Error extracting', absolute, e)\n",
        "                elif absolute.suffix.lower() in ('.glb', '.gltf') and absolute not in processed:\n",
        "                    processed.add(absolute)\n",
        "                    dst = OUT_DIR / absolute.name\n",
        "                    shutil.copy2(absolute, dst)\n",
        "                    print('Copied:', dst)\n",
        "                    extracted += 1\n",
        "    for child in tile.get('children', []):\n",
        "        process_tile(child, base_path)\n",
        "\n",
        "for ts in tileset_paths:\n",
        "    try:\n",
        "        js = json.loads(ts.read_text(encoding='utf-8'))\n",
        "    except Exception as e:\n",
        "        print('Parse error', ts, e); continue\n",
        "    root = js.get('root')\n",
        "    if root:\n",
        "        process_tile(root, ts.parent)\n",
        "    else:\n",
        "        for t in js.get('tiles', []):\n",
        "            process_tile(t, ts.parent)\n",
        "\n",
        "print('Extracted count:', extracted)\n",
        "\n",
        "if ZIP_PATH.exists():\n",
        "    ZIP_PATH.unlink()\n",
        "shutil.make_archive(str(ZIP_PATH.with_suffix('')), 'zip', root_dir=OUT_DIR)\n",
        "print('Zipped to:', ZIP_PATH)\n",
        "\n",
        "print('\\nDone. Download /kaggle/working/output_glb.zip from the Notebook Output pane.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# 4) 出力フォルダの中身確認（任意）\n",
        "!ls -la /kaggle/working/output_glb || true\n",
        "!ls -la /kaggle/working/output_glb.zip || true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実行後に `output_glb.zip` をここにアップロードしてください。私が中身を確認して、渋谷センター街・スクランブル交差点周辺だけを抽出／結合／gltf 展開などを行います。必要な出力形式（single .glb / unpacked .gltf + textures / 個別 .glb をそのまま）を教えてください。"
      ]
    }
  ]
}